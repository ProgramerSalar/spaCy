{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Multi-Word Token Entities and RegEx in spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Key Concepts in this Notebook\n",
    "\n",
    "1. Working with Multi-Word Tokens and RegEx in spaCy 3x \n",
    "2. RegEx finditer \n",
    "3. Spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Problems with Multi-Word Tokens in spaCy as Entities¶\n",
    "As we saw in 01.03: Rules-Based NER, we can use spaCy’s Matcher to grab multi-word tokens, or tokens that span multiple tokens. The main problem with this, however, is that these multi-word tokens are not placed into the doc.ents. This means that we cannot access them the same way we would other entities. In this notebook, we will figure out how to solve that problem with a simple workflow:\n",
    "\n",
    "Extract Multi-Word Tokens with re.finditer()\n",
    "\n",
    "Reconstruct the spans in the spaCy doc\n",
    "\n",
    "Give priority to longer spans (Optional)\n",
    "\n",
    "Inject the Spans into doc.ents\n",
    "\n",
    "We will cover each of these steps in turn.\n",
    "\n",
    "## 9.3. Extract Multi-Word Tokens¶\n",
    "First, we need to grab the multi-word tokens. In this notebook, we are going to try and grab a multi-word token. In this case, a person whose first name begins with Paul. In the RegEx below, we specify that we are looking for any string that starts with “Paul” and then is followed by a capitalized letter. We then tell it to grab the entire second word until the end of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 11), match='Paul Newman'>\n",
      "<re.Match object; span=(39, 53), match='Paul Hollywood'>\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\"\n",
    "\n",
    "pattern = r\"Paul [A-Z]\\w+\"\n",
    "\n",
    "matches = re.finditer(pattern, text)\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression r\"Paul [A-Z]\\\\w+\" is designed to match strings that start with “Paul” followed by a space, then an uppercase letter from A to Z, and one or more word characters (which include letters, digits, and underscores). Here’s a breakdown of the pattern:\n",
    "\n",
    "\n",
    "* r: This denotes a raw string in Python, which tells the interpreter to treat backslashes as literal characters and not as escape characters.\n",
    "* \"Paul \": This matches the literal string “Paul” followed by a space.\n",
    "* [A-Z]: This is a character class that matches any single uppercase letter from A to Z.\n",
    "* \\\\w+: The double backslash is used to escape the backslash character itself because we are in a raw string. \\w matches any word character (equivalent to [a-zA-Z0-9_]), and the + signifies that the \\w pattern must occur one or more times.\n",
    "\n",
    "So, this regular expression will match any string that begins with “Paul” followed by an uppercase letter and at least one more word character. For example, it would match “Paul Aardvark” but not “Paul aardvark” (due to the lowercase ‘a’) or “Paul” (since there are no characters after the space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have not grabbed the final “Paul” which is not followed by a last name. In this case, we are not interested in that Paul. Now that we know how to grab the multi-word tokens, we need to have a way to parse them in spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Reconstruct Spans¶\n",
    "This next stage is a bit more complicated, but works quite well once you understand the process. First, we need to import the libraries we will need. Note that we are also adding Span from spacy.tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\"\n",
    "pattern = r\"Paul [A-Z]\\w+\"\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Even though this part is unnecessary, it is good to do it here because in other situations you will have entities. If you do, you need to store them as a separate list to which we will append things.\n",
    "original_ents = list(doc.ents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will create a blank spaCy English model and create the doc object of the text. It will have no entities in it because we are working with a blank model that does not have an “ner” component.\n",
    "\n",
    "- Now, let’s iterate over the results from re.finditer(). In this cell, we are goingg to grab the start and end from each match. we will then create a temporary span that will be equal to where the characters start and end in the doc object. This is important because tokens and characters do not always align correctly. Finally, we append to mwt_ents, the start, end, and text. The text is not necessary but it will help with debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwt_ents = []\n",
    "for match in re.finditer(pattern, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    if span is not None:\n",
    "        mwt_ents.append((span.start, span.end, span.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Inject the Spans into the doc.ents¶\n",
    "With that data, we can iterate over each entity and identify where it begins and ends in spaCy. Note, we are using the spaCy Span class. This allows us to create a span object and assign it a custom label. With this data, we can append each Span to original_ents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "for ent in mwt_ents:\n",
    "    start, end, name = ent \n",
    "    per_ent = Span(doc, start, end, label=\"PERSON\")\n",
    "    original_ents.append(per_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Finally, we set doc.ents equal to original_ents. This effectively loads the spans back into the spaCy doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents = original_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman PERSON\n",
      "Paul Hollywood PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these are now properly identified entities in our doc.ents class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6. Give priority to Longer Spans¶\n",
    "Sometimes, the situation is not so neat. Sometimes our custom RegEx entities will overlap with spaCy’s Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman PERSON\n",
      "American NORP\n",
      "Paul Hollywood PERSON\n",
      "British NORP\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import spacy\n",
    "\n",
    "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host.\"\n",
    "pattern = r\"Hollywood\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code pattern = r\"Hollywood\" defines a regular expression pattern in Python that matches the exact string “Hollywood”. Here’s a breakdown of the code:\n",
    "\n",
    "* pattern: This is a variable name that is being assigned the regular expression.\n",
    "* r: This prefix before the string literal indicates a raw string in Python. In raw strings, backslashes are treated as literal characters and not as escape characters.\n",
    "* \"Hollywood\": This is the string literal that specifies the pattern to mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say that we create a new entity. Maybe words associated with Cinema. So, we want to classify Hollywood as a tag “CINEMA”. Now, in the above text, Hollywood is clearly associated with Paul Hollywood, but let’s imagine for a moment that it is not. Let’s try and run the same code as above. If we do, we notice that we get an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output “British NORP” refers to the classification of “British” as a Nationality, Religious, or Political group. In the context of natural language processing (NLP) and entity recognition, “NORP” is a common label used to identify mentions of national, religious, or political groups within a text. So, when an NLP system outputs “British NORP”, it indicates that the word “British” has been recognized as referring to the national identity of the United Kingdom or its people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shah Rukh Khan PERSON\n",
      "SRK ORG\n",
      "Indian NORP\n",
      "Hindi GPE\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import spacy\n",
    "\n",
    "text = \"Shah Rukh Khan, also known by the initialism SRK, is an Indian actor and film producer who works in Hindi films.\"\n",
    "pattern = r\"Bollywood\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1010] Unable to set entity information for token 9 which is included in more than one span in entities, blocked, missing or outside.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     original_ents\u001b[38;5;241m.\u001b[39mappend(per_ent)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# print(original_ents)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ments\u001b[49m \u001b[38;5;241m=\u001b[39m original_ents\n",
      "File \u001b[1;32mc:\\Users\\Manjusha Kumari\\.conda\\envs\\manish\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:795\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Manjusha Kumari\\.conda\\envs\\manish\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:832\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E1010] Unable to set entity information for token 9 which is included in more than one span in entities, blocked, missing or outside."
     ]
    }
   ],
   "source": [
    "mwt_ents = []\n",
    "original_ents = list(doc.ents)\n",
    "# original_ents\n",
    "\n",
    "for match in re.finditer(pattern, doc.text):\n",
    "    # print(match)\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # print(span)\n",
    "    if span is not None:\n",
    "        mwt_ents.append((span.start, span.end, span.text))\n",
    "        # print(mwt_ents)\n",
    "\n",
    "for ent in mwt_ents:\n",
    "    # print(ent)\n",
    "    start, end, name = ent \n",
    "    # print(start)\n",
    "    per_ent = Span(doc, start, end, label=\"CINEMA\")\n",
    "    # print(per_ent)\n",
    "    original_ents.append(per_ent)\n",
    "    # print(original_ents)\n",
    "\n",
    "doc.ents = original_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error tells us that one of our tokens from the finditer() overlapped with one that our “ner” component found. This is a problem that can be rectified with spaCy’s filter_spans. This gives primacy to longer spans. Notice how we have allowed the Paul Hollywood entity to be a PERSON, rather than CINEMA. This is because Hollywood is shorter than Paul Hollywood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The error ValueError: [E1010] Unable to set entity information for token 9 which is included in more than one span in entities, blocked, missing or outside occurs in spaCy when you try to assign overlapping entities to a Doc object. This happens when two or more entities are defined to include the same token, which is not allowed in spaCy’s data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO resolve this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman PERSON\n",
      "American NORP\n",
      "Paul Hollywood PERSON\n",
      "British NORP\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import filter_spans\n",
    "\n",
    "filterd = filter_spans(original_ents)\n",
    "# print(filterd)\n",
    "doc.ents = filterd\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
