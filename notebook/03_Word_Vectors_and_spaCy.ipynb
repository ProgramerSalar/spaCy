{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. word vector and spaCy\n",
    "\n",
    "in this notebook is word vectors, or word embeddings. Because the English small model does not have these saved. we will be working with the next largest model, the English medium model, **en_core_web_md**. Let's import spaCy and download medium model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "     ---------------------------------------- 0.0/42.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/42.8 MB 6.8 MB/s eta 0:00:07\n",
      "      --------------------------------------- 1.0/42.8 MB 11.0 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 1.3/42.8 MB 9.4 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.6/42.8 MB 8.7 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.8/42.8 MB 7.8 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 2.1/42.8 MB 7.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 2.4/42.8 MB 7.5 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 2.6/42.8 MB 7.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 2.9/42.8 MB 7.3 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 3.1/42.8 MB 7.0 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.3/42.8 MB 7.0 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.6/42.8 MB 6.9 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.8/42.8 MB 6.9 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 4.1/42.8 MB 6.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 4.3/42.8 MB 6.9 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 4.6/42.8 MB 6.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 4.8/42.8 MB 6.7 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 5.1/42.8 MB 6.8 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 5.4/42.8 MB 6.6 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 5.6/42.8 MB 6.6 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 5.9/42.8 MB 6.6 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 6.1/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 6.4/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 6.7/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 6.9/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 7.2/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 7.4/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 7.7/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 8.0/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 8.3/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     ------- -------------------------------- 8.5/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 8.7/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 9.0/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 9.3/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 9.5/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 9.8/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 10.1/42.8 MB 6.4 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 10.4/42.8 MB 6.5 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 10.6/42.8 MB 6.3 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 10.9/42.8 MB 6.2 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 11.2/42.8 MB 6.1 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 11.5/42.8 MB 6.1 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 11.8/42.8 MB 6.1 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 12.0/42.8 MB 6.1 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 12.2/42.8 MB 6.1 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 12.5/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 12.7/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 13.0/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 13.2/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 13.4/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 13.7/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 14.0/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 14.3/42.8 MB 6.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 14.5/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 14.8/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 15.0/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 15.3/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 15.6/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 15.9/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 16.1/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 16.4/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 16.7/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 16.9/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 17.2/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 17.5/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 17.9/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 18.1/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 18.5/42.8 MB 6.1 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 18.8/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 19.1/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 19.3/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 19.6/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 19.8/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 20.1/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 20.4/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 20.7/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 21.0/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 21.3/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 21.6/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 21.8/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 22.1/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 22.4/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 22.6/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 22.9/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 23.2/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     --------------------- ------------------ 23.5/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 23.8/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 24.1/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 24.3/42.8 MB 6.1 MB/s eta 0:00:04\n",
      "     ----------------------- ---------------- 24.6/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.9/42.8 MB 6.0 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 25.1/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 25.4/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.7/42.8 MB 6.0 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 26.1/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 26.3/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 26.6/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 26.9/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 27.2/42.8 MB 6.0 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 27.5/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 27.8/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 28.1/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 28.3/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 28.6/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 28.9/42.8 MB 6.0 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 29.2/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 29.5/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 29.8/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 30.0/42.8 MB 6.0 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 30.3/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 30.6/42.8 MB 6.1 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 30.8/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 31.1/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 31.4/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 31.7/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 31.9/42.8 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 32.2/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 32.5/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 32.7/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 32.9/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 33.2/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 33.5/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 33.8/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 34.1/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 34.4/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 34.7/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 35.0/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 35.3/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.6/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 35.8/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 36.1/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.4/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.7/42.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 37.0/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 37.3/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 37.6/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 37.9/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 38.2/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.5/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.8/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 39.0/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 39.3/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 39.6/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 39.9/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 40.2/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 40.5/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.8/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.1/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.4/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.7/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.0/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.8/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.8/42.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.8/42.8 MB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from en-core-web-md==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "# print(nlp)\n",
    "with open (\"F:\\spaCy-master\\data\\wiki_us.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    # print(text)\n",
    "    doc = nlp(text)\n",
    "    # print(doc)\n",
    "    sentence1 = list(doc.sents)[0]\n",
    "    print(sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 word vectors \n",
    "\n",
    "word vectors, or word embeddings, are numerical representation of words in multidimensional space through matrics. The purpose of the word vecor is to get a computer system to understand a word. Computer cannot understand text efficiently. They can, however, process number quickly and well. for this reason it is important to convert a word into a number\n",
    "\n",
    "\n",
    "initial methods for creating word vectors in a pipeline take all words in a corpus and covert them into a single unique number. these words are then stored in a dictonary that would look like this: {\"this\":1, \"a\":2} etc. This is know as bag of words. This approch to representing word numerically, however, only allow a computer to understand words numerically to identify to identify unique words. it does ot howerver allow a computer understand meaning.\n",
    "\n",
    "Imagine this scenario:\n",
    "\n",
    "Tom loves to eat chocolate.\n",
    "\n",
    "Tom likes to eat chocolate.\n",
    "\n",
    "These sentences represented as a numerical array (list) would look like this:\n",
    "\n",
    "1, 2, 3, 4, 5\n",
    "\n",
    "1, 6, 3, 4, 5\n",
    "\n",
    "As we can see, as humans both sentences are nearly identical. The only difference is the degree to which Tom appreciates eating chocolate. If we examine the numbers, however, these two sentences seem quite close, but their semantical meaning is impossible to know for certain. How similar is 2 to 6? The number 6 could represent “hates” as much as it could represent “likes”. This is where word vectors come in.\n",
    "\n",
    "Word vectors take these one dimensional bag of words and gives them multidimensional meaning by representing them in higher dimensional space, noted above. This is achieved through machine learning and can be easily achieved via Python libraries, such as Gensim, which we will explore more closely in the next notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 why use word vectors ?\n",
    "\n",
    "the goal of word vector is to achieve numerical understanding of language so that a computer can perform more complex tasks on that corpus. Let's consider to example above. How do we get a computer to understand 2 and 6 are synonyms or mean something similar? One option you might be thinking is to simply give the computer a synonyms dictionary. it can look up synonyms and then know what words mean. this approach, on the surface make perform sense, but let's explore that option and see why it cannot possibly work. \n",
    "\n",
    "for the example below we will using the python library PyDictionary with allow us to look up difinitions and synonyms of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting goslate\n",
      "  Cloning https://github.com/yeahwhat-mc/goslate.git to c:\\users\\manjusha kumari\\appdata\\local\\temp\\pip-install-uml438m5\\goslate_f974e8c654ea452cb2438a05b931ba81\n",
      "  Resolved https://github.com/yeahwhat-mc/goslate.git to commit d6d511a9c001fe0b5c1cf947fd650770e9794f1d\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: goslate\n",
      "  Building wheel for goslate (setup.py): started\n",
      "  Building wheel for goslate (setup.py): finished with status 'done'\n",
      "  Created wheel for goslate: filename=goslate-1.4.0-py3-none-any.whl size=8474 sha256=d9008b5328b8c18103836a9adf63082819bde1ee1ad979e2585a9ff9d63b07ef\n",
      "  Stored in directory: C:\\Users\\Manjusha Kumari\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-r_1xhsdd\\wheels\\b4\\38\\a9\\671017557f39192003435f1a1d788cf330998a5c91c6b278f5\n",
      "Successfully built goslate\n",
      "Installing collected packages: goslate\n",
      "Successfully installed goslate-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/yeahwhat-mc/goslate.git 'C:\\Users\\Manjusha Kumari\\AppData\\Local\\Temp\\pip-install-uml438m5\\goslate_f974e8c654ea452cb2438a05b931ba81'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/yeahwhat-mc/goslate.git#egg=goslate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyDictionary\n",
      "  Using cached PyDictionary-2.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting bs4 (from PyDictionary)\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDictionary) (8.1.7)\n",
      "Requirement already satisfied: goslate in c:\\users\\manjusha kumari\\appdata\\roaming\\python\\python311\\site-packages (from PyDictionary) (1.4.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDictionary) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4->PyDictionary) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->PyDictionary) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->PyDictionary) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->PyDictionary) (2.5)\n",
      "Downloading PyDictionary-2.0.1-py3-none-any.whl (6.1 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4, PyDictionary\n",
      "Successfully installed PyDictionary-2.0.1 bs4-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram has no Synonyms in the API\n",
      "Ram: None\n",
      "\n",
      "eats has no Synonyms in the API\n",
      "eats: None\n",
      "\n",
      "mango has no Synonyms in the API\n",
      "mango: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PyDictionary import PyDictionary\n",
    "\n",
    "dictionary = PyDictionary()\n",
    "# print(dictionary)\n",
    "\n",
    "text = \"Tom loves to eat chocolate\"\n",
    "words = text.split()\n",
    "for word in words:\n",
    "    # print(word)\n",
    "    syns = dictionary.synonym(word)\n",
    "    print(f\"{word}: {syns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The output you’re seeing indicates that the PyDictionary module was unable to find synonyms for the words “Ram,” “eats,” and “mango” using its API. This could be due to several reasons:\n",
    "\n",
    "* The word may not have synonyms listed in the source that PyDictionary is using, which is typically Thesaurus.com1.\n",
    "The API or the code within PyDictionary that fetches the synonyms is outdated or broken. There have been reports that PyDictionary is not actively maintained, and its synonym function may be looking for HTML structures on Thesaurus.com that no longer exist12.\n",
    "There might be a connectivity issue or a temporary problem with the API service.\n",
    "If you’re consistently getting this error for different words, it’s likely that the issue is with the PyDictionary module itself rather than the specific words. In such cases, you might want to consider using an alternative package or method to find synonyms. For example, you could use the WordHoard package, which is designed to find semantic relationships between words, including synonyms2.\n",
    "\n",
    "\n",
    "\n",
    "* Even with the simple sentence, the results are comically bad. Why? The reason is because synonym substitution, a common method of data augmentation, does not take into account syntactical differences of synonyms. I do not believe anyone would think “Felis domesticus”, the Latin name of the common house cat, would be an adequite substitution for the name Tom. Nor is “garbage down” a really proper synonym for eat.\n",
    "\n",
    "Perhaps, then we could use synonyms to find words that have cross-terms, or terms that appear in both synonym sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wordhoard.synonyms.Synonyms object at 0x000001EC50DA5210>\n"
     ]
    }
   ],
   "source": [
    "from wordhoard import Synonyms\n",
    "\n",
    "word = \"life\"\n",
    "results = Synonyms(search_string=word, output_format='json').find_synonyms()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would give you a JSON object with a list of synonyms for the word “life.” You can replace “life” with any other word you’re interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram: ['bang', 'bash', 'bump', 'collide', 'crash', 'hit', 'impact', 'impinge', 'knock', 'slam', 'smash', 'strike', 'swipe']\n",
      "\n",
      "eats: ['chow', 'chuck', 'grub']\n",
      "\n",
      "mango: ['edible fruit', 'mangifera indica', 'mango tree']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"Ram eats mango\"\n",
    "words = text.split()\n",
    "# print(word)\n",
    "for word in words:\n",
    "    # print(word)\n",
    "    results = Synonyms(search_string=word).find_synonyms()\n",
    "    print(f\"{word}: {results}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "### 3.1.2 what do word vectors Look Like ?\n",
    "\n",
    "Word vectors have a preset number of dimensions. These dimensions are honed via machine learned. Models take into account word frequency alongside words across a corpus and the appearance of other words in similar contexts. This allows for the the computer to determine the syntactical similarity of words numerically. It then needs to represent these relationships numerically. It does this through the vector, or a matrix of matrices. To represent these more concisely, models flatten a matrix to a float (decimal number). The number of dimensions represent the number of floats in the matrix.\n",
    "\n",
    "Let’s take a look at the first word in our sentence. Specifically, let’s look at its vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.027637  , -1.3026294 , -0.2781941 ,  2.0594873 ,  6.0170302 ,\n",
       "       -0.08175199, -0.11235202,  0.8837014 ,  2.563658  , -2.758028  ,\n",
       "        6.6160507 ,  1.346154  , -1.6630094 ,  1.5930657 , -0.8227061 ,\n",
       "        3.9117258 , -0.25638437,  4.5746174 , -0.8876056 , -4.0403757 ,\n",
       "        0.18477502, -1.661304  , -4.408809  ,  3.338869  ,  1.6343212 ,\n",
       "       -1.7847955 , -1.37701   , -2.1039028 ,  0.12374973, -1.7991323 ,\n",
       "       -0.77667576,  0.61342263, -2.276551  , -0.17765899, -4.983436  ,\n",
       "       -0.9012372 , -0.2532391 ,  0.14819527, -1.0962433 , -1.5416864 ,\n",
       "        0.8260357 , -0.785282  , -0.72377604,  2.4843237 , -1.8458848 ,\n",
       "        1.9493299 ,  0.00873733,  1.4303114 , -0.31169796, -1.7525452 ,\n",
       "       -1.773963  ,  2.0376918 ,  0.26388973, -2.5224395 ,  0.1784055 ,\n",
       "        2.104084  , -0.21009296,  0.03062047, -1.1003472 ,  0.48895955,\n",
       "       -0.9144515 , -3.2816818 , -1.1192304 ,  0.8974213 ,  3.6872    ,\n",
       "        0.944662  , -1.2556393 , -1.8996325 ,  0.9479642 ,  0.9267576 ,\n",
       "       -0.59638745, -2.4400108 , -2.6817768 ,  2.2768605 ,  1.1972209 ,\n",
       "        1.2334495 , -4.379217  ,  1.8100827 , -1.2302446 ,  2.7670221 ,\n",
       "       -1.5494436 ,  0.50601494, -0.49824798,  3.3807135 ,  1.513089  ,\n",
       "       -1.960272  , -3.0806563 , -3.2850997 ,  1.7676389 ,  0.19253492,\n",
       "        1.5983899 , -0.59738404,  0.6637903 , -1.3172249 , -0.87066334,\n",
       "       -1.4948834 , -0.47841206,  0.79311234, -1.2837962 ,  2.5462892 ,\n",
       "        2.5481594 ,  0.75574833,  1.173465  ,  3.5765    ,  0.85520947,\n",
       "        4.5327277 ,  3.1696498 , -2.7503035 ,  0.30922374, -3.0135915 ,\n",
       "        2.8130014 ,  0.07208141, -1.6768472 ,  0.8675361 , -0.07153   ,\n",
       "       -0.72297406,  1.2320777 ,  2.0473638 ,  0.05854434, -3.1940184 ,\n",
       "        2.242601  , -3.1005251 ,  2.8782167 ,  0.90646136, -2.4048872 ,\n",
       "       -5.4257903 , -0.71864724, -5.1605806 ,  5.183388  , -1.9535464 ,\n",
       "       -1.8738999 ,  0.09448621,  3.6440604 ,  0.5615559 ,  2.2842135 ,\n",
       "        0.06238667, -1.4392354 ,  0.4409809 , -1.401644  , -1.803578  ,\n",
       "       -1.0415776 ,  0.23931481,  0.46186438,  1.7991687 ,  0.8433639 ,\n",
       "        0.53565043, -3.7142973 , -0.9568531 ,  1.4532119 ,  0.4140856 ,\n",
       "       -1.5636023 ,  1.6597761 , -0.53611046,  2.5832176 , -0.630107  ,\n",
       "       -0.71606535,  1.612792  ,  1.4550165 ,  1.7835562 ,  0.01313564,\n",
       "        0.7551937 , -0.650618  ,  1.5700488 ,  3.9252603 , -2.9749167 ,\n",
       "       -2.006214  , -3.299329  ,  2.628225  ,  1.4635404 ,  1.1598089 ,\n",
       "        0.4601238 , -1.2250909 ,  1.210806  ,  0.2997115 ,  0.0843806 ,\n",
       "        1.9017812 ,  0.48440495, -0.8380168 , -3.7706513 ,  0.11377706,\n",
       "       -1.6039883 , -1.8053327 , -2.1347682 , -1.1738442 , -1.2363669 ,\n",
       "        1.870999  , -1.0571265 ,  2.9955986 , -0.8787782 ,  0.9485921 ,\n",
       "        0.27803287, -4.8149085 ,  0.24630463, -1.8826227 ,  2.944273  ,\n",
       "        3.6437259 , -5.8248925 , -2.8403106 ,  1.6839985 , -2.5544844 ,\n",
       "        2.0473416 , -0.34774002,  0.45497918,  0.12032903,  5.7503033 ,\n",
       "        0.94782776, -4.8768625 ,  1.9549491 , -0.43733788, -0.772645  ,\n",
       "        2.4860134 ,  1.1169791 , -2.4220138 , -0.24523993,  2.4553814 ,\n",
       "        0.20744298,  0.3372685 , -5.200365  ,  0.90124375,  0.8829774 ,\n",
       "       -0.6121268 ,  0.7870248 , -0.8947056 , -0.78008276, -2.464697  ,\n",
       "       -0.24589758,  0.2572514 ,  1.0458548 ,  2.4333563 ,  0.31987348,\n",
       "        3.3279161 , -1.5730971 , -0.26007158,  1.0928699 ,  1.3398259 ,\n",
       "        0.8783041 ,  2.02874   , -0.33798987, -0.47549438, -1.3818715 ,\n",
       "        0.3828692 ,  0.26382294,  2.128372  ,  2.5246186 , -1.0263755 ,\n",
       "       -0.05870475, -2.242809  , -0.07310911, -3.313034  ,  3.221643  ,\n",
       "        2.8987906 , -4.4306817 , -4.6721315 , -0.03341851,  1.6217276 ,\n",
       "       -1.7908937 ,  1.9199018 , -2.9250276 ,  2.1744938 , -0.04540499,\n",
       "       -1.8260009 ,  5.1214986 ,  1.3917719 ,  1.5722642 , -1.4982871 ,\n",
       "        0.0166382 ,  1.6882787 ,  0.14555307, -2.4490569 ,  0.3505087 ,\n",
       "        1.5317487 ,  2.0554888 ,  3.130987  , -0.37880036,  0.78455704,\n",
       "        0.8198804 ,  0.15660644, -1.9917842 ,  1.3065898 ,  1.3198344 ,\n",
       "        4.0062265 , -0.36959887,  2.2111504 ,  0.34412047, -0.8258745 ,\n",
       "       -0.90041506,  1.0451168 ,  3.342414  ,  0.7353282 ,  2.0737743 ,\n",
       "       -0.32040203,  0.03274616, -0.6173663 , -0.40958607,  0.33468273,\n",
       "        1.9727722 ,  1.571036  , -3.2585914 , -0.3228874 ,  0.62857   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Why use word Vectors ?\n",
    "Once a word vector model is trained, we can do similarity matches very quickly and very reliably. Let’s explore some vectors from our medium sized model. Let’s specifically try and find the words most closely related to the word dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogsbody: [1.     0.8334 0.8221 0.8108 0.7856 0.7195 0.685  0.6328 0.6148 0.5966]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Define the word you want to find similarities for\n",
    "your_word = \"dog\"\n",
    "\n",
    "# Get the vector for your word from the vocabulary\n",
    "query_vector = np.asarray([nlp.vocab.vectors[nlp.vocab.strings[your_word]]])\n",
    "\n",
    "# Find the most similar words using the vector\n",
    "ms = nlp.vocab.vectors.most_similar(query_vector, n=10)\n",
    "\n",
    "# Extract the words and their similarity scores\n",
    "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "distances = ms[2]\n",
    "\n",
    "# Print the similar words and their similarity scores\n",
    "for word, distance in zip(words, distances):\n",
    "    print(f\"{word}: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogsbody', 'wolfdogs', 'Baeg', 'duppy', 'pet(s', 'postcanine', 'Kebira', 'uppies', 'Toropets', 'moggie']\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/54717449/mapping-word-vector-to-the-most-similar-closest-word-using-spacy\n",
    "your_word = \"dog\"\n",
    "\n",
    "ms = nlp.vocab.vectors.most_similar(\n",
    "    np.asarray([nlp.vocab.vectors[nlp.vocab.strings[your_word]]]), n=10)\n",
    "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "distances = ms[2]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Doc Similarity  \n",
    "\n",
    "in spacy we can do this same thing at the document level. Through word vectors we can calculate the simalarity between two document. Let's take example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and humburgers. <-> Fast food tasts very good. accuracy: 0.6565092671761303\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "# print(nlp)\n",
    "\n",
    "doc1 = nlp(\"I like salty fries and humburgers.\")\n",
    "doc2 = nlp(\"Fast food tasts very good.\")\n",
    "# doc2 = nlp(\"dog is good.\")\n",
    "\n",
    "# similarity b/w two document \n",
    "print(doc1, \"<->\", doc2, \"accuracy:\", doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Word Similarity \n",
    "\n",
    "we can also calculate the similarity b/w two given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salty fries <-> salty , [accuracy: 0.8082310557365417 ]\n"
     ]
    }
   ],
   "source": [
    "# similarity of token and spans \n",
    "french_fries = doc1[2:4]\n",
    "# print(french_fries)\n",
    "burger = doc1[2]  # in this section 2 means -> 2nd word of line not character \n",
    "# print(burger)\n",
    "\n",
    "print(french_fries, \"<->\", burger, \", [accuracy:\", french_fries.similarity(burger), \"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "a\n",
      "l\n",
      "t\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "# how i access the character of the word in this code \n",
    "\n",
    "# similarity of token and spans \n",
    "french_fries = doc1[2:4]\n",
    "# print(french_fries)\n",
    "burger = doc1[2]  # in this section 2 means -> 2nd word of line not character\n",
    "\n",
    "for i in str(burger):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Conclusion \n",
    "\n",
    "As we have seen in this notebook, spaCy is made up of a series of complex P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
